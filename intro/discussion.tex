% !TEX root = ../main-ring-signature.tex

\subsubsection{Extending our technique.}
A natural question is if this technique can be applied once again. That is, to compute a $\Theta(\sqrt[4]{n})$  proof, compute commitments to an element from $H=\{h(A_1),\ldots,h(A_{n^{3/4}})\}$
%and
%$G=\allowbreak\{
%	g_{[\matr{A}_1]}
%		([
%			\vecb{\kappa}_1]),
%	\ldots,\allowbreak
%	g_{[\matr{A}_{n^3/4}]}
%		([
%			\vecb{\kappa}_{n^{3/4}}
%])\}$,
and then prove that it belongs to $H$ using our set membership proof of size $\Theta(\sqrt[3]{n})$. Since $|H|=n^{3/4}$, the proof will be of size $\Theta(\sqrt[3]{n^{3/4}})=\Theta(\sqrt[4]{n})$. However, this is not possible since the $\Theta(\sqrt[3]{n})$ proof is not a set-membership proof for arbitrary sets and in fact it doesn't work for elements in the image of $h$. Going a step forward, the proof works for elements of the form $(a\cP_s,a^2\cP_s)$, where $a$ is an integer and $\cP_s$ is a generator of one of the base groups of a bilinear group. On the other hand, the image of $h$ contains elements of the form $\sum_{i=1}^m (a_i\cP_s,a_i^2\cP_s)$ for which we do not know how to construct a function like $h$ and thus, we do not how to construct a set membership proof of size $\Theta(\sqrt[3]{n})$.


%\subsubsection{Getting rid of the Permutation Pairing Assumption.} Gonzalez et al.~\cite{ACNS:GonRaf16} modify Groth and Lu's proof of correctness of a shuffle \cite{AC:GroLu07} to get rid of the permutation pairing assumption. They showed that the statement ``I know two vectors of group elements $(\vecb{a}_1,\ldots,\vecb{a}_m),(\vecb{a}'_1,\ldots,\vecb{a}'_m)$ which are equal up to a permutation'' can be showed with $m$ set membership proofs that $\vecb{a}'_1,\dots\vecb{a}'_m\in\{\vecb{a},\ldots,\vecb{a}_m\}$ and  a proof that$\sum_{i=1}^m \vecb{a}'_i=\sum_{i=1}^m \vecb{a}_i$.  Gonzalez et al.~construct a $\Theta(m)$ proof of the first statement under standard assumptions (DLin in symmetric groups), while the second statement can be proved using standard techniques.

%If we use Gonzalez et al.'s techniques we would have to show that for all $\vecb{a}'\in A',$ $\vecb{a}'\in A_ \mu$. However, we can't do this since $A_\mu$ is unknown to the verifier. Instead, it seems that we are using stronger properties of the permutation pairing assumption. We use $h(A_\mu)$ as a constant-size computationally binding commitment of the set $A_\mu$, i.e.~invariant under permutations of the input, which is also structure preserving, i.e.~$A_\mu\subset\GG^2_1$ and $h(A_\mu)\in\GG_1$. It is an interesting open problem to construct $h$ from standard assumptions (e.g.~DDH, DLin).

\subsubsection{Relation to \cite{AC:GonHevRaf15}.}
Our construction is similar to the set membership proof of Gonzalez et al.~{\cite[Appendix D.2]{AC:GonHevRaf15} also of size $\Theta(\sqrt[3]{n})$. There, the CRS contains a matrix $\matr{A}$ (which resembles our set $A$) that is used to compute $\sqrt[3]{n}$ hashes (or binding commitments) of $n^{2/3}$ of subsets of verification keys of size $\sqrt[3]{n}$. Then some hidden hash is shown to belong to the set fo $n^{2/3}$ hashes. These hashes are computed as a linear combination of a the columns of $\matr{A}$ with the verification keys.
Of course, this prevents signatures for rings containing public keys generated after the CRS generation.

The novelty of our scheme is a distributed generation, at signature time, of the matrix $\matr{A}$, such that each public key contributes with a constant number of coefficients of $\matr{A}$. This implies that now each hash is computed using different coefficients of $\matr{A}$. But then proving that the hidden hash was honestly computed is much more tricky. Indeed, is essential to include our hash function $h$ which computes a digest for a particular set of coefficients of $\matr{A}$.

\subsection{Erasures} \label{sect:erasures}
In the security proof we need to embed a random preimage $A=\{\vecb{a}_1,\ldots,\allowbreak \vecb{a}_{q_{\mathsf{gen}}}\}$ of $h$ in the verification keys, where $q_{\mathsf{gen}}$ is the total number of verification keys. On the other hand, the adversary may adaptively corrupt parties obtaining all the random coins used to generate the verification key. That is, we need to reveal $\log_{\cP_S} \vecb{a}_i$ (the discrete logs of $\vecb{a}_i$) to the adversary, which is incompatible with the permutation pairing assumption and thus with the security of $h$. Since is not clear how to obliviously sample $(a_i\cP,a^2_i\cP)$ and we can only guess the set of corrupted parties with negligible probability, we are forced to use erasures: after sampling $a_i$ and computing $\vecb{a}_i$, the key generation algorithm erases $a_i$ and $a_i^2$.

Erasures were considered by Bender et al.~\cite{TCC:BenKatMor06} but only with respect to anony\-mity. Our signature achieves the stronger notion of perfect anonymity of Chandran et al.~\cite{ICALP:ChaGroSah07}, meaning that, information theoretically, there is nothing in the signature that binds a signer to a signature. Since the random coins of our key generation algorithm are completely determined by the public key, in the information theoretic setting it is irrelevant if parties erase or not part of their random coins.

On the other hand, erasures in the unforgeability experiment seems to have not received much attention. In fact, the definition of Bender et al.~doesn't prevent erasures, since, after corrupting a party, the adversary receives only the secret key but not the random coins used by the key generation algorithm.  Chandran et al.'s unforgeability definition explicitly includes the random coins in the adversary view, preventing any erasure. However, this is not discussed and further, erasures are not even mentioned in their work.

We would also like to point out that other schemes may also require erasures. This is the case Malavolta et al.'s CRS-less ring signature. In order to get rid of the CRS, which is a pair of Groth-Sahai commitment keys, each party appends its own Groth-Sahai commitment keys to its public key. The signer and the verifier combines all the commitment keys by simply adding them and, as long as at least one verification key was honestly generated, the combined commitment keys are correctly distributed.

Nevertheless, when proving unforgeability one needs to move from perfectly hiding commitment keys to perfectly binding commitment keys. This implies that the reduction must change itself the verification keys of all the users to perfectly binding ones. In the perfectly hiding setting commitment keys are chosen as $\vecb{u}_1 = \lambda\vecb{u}_2$ and $\vecb{u}_2 = (a\mathcal{P},\mathcal{P})^\top$, for a random $\lambda$ and random $a$.  On the other hand, perfectly binding commitments keys have the only difference that $\vecb{u}_1 = (\mathcal{P},0)^\top+\lambda\vecb{u}_2$.
An adversary that dynamically corrupts parties will eventually gets access to $\lambda$ and $a$, which clearly allows him to detect any change on the commitment keys. We believe is an interesting open question if this problem can be fixed.


